{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Thực thi forward pass của mạng\n",
    "## 3.1 Khai báo mạng\n",
    "Như tôi đã chỉ ra trước đó, chúng tôi sử dụng class `nn.Module` để xây dựng các kiến trúc tùy chỉnh trong PyTorch. Hãy để chúng tôi khai báo một mạng cho chương trình phát hiện đối tượng. Trong tệp `darknet.py`, chúng tôi thêm class sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, cfgfile):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(cfgfile)\n",
    "        self.net_info, self.module_list = create_modules(self.blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây, chúng ta đã phân lớp con của lớp `nn.Module` và đặt tên cho lớp của chúng ta là `Darknet`. Chúng tôi khởi tạo mạng với các thành viên, `block`, `net_info` và `module_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Thực thi forward pass của mạng\n",
    "Forward pass của mạng được thực hiện bằng cách ghi đè phương thức `forward` của lớp `nn.Module`.\n",
    "\n",
    "`forward` phục vụ hai mục đích. Đầu tiên, để tính toán kết quả đầu ra và thứ hai, để biến đổi các bản đồ tính năng phát hiện đầu ra theo cách mà nó có thể được xử lý dễ dàng hơn (chẳng hạn như biến đổi chúng để các bản đồ phát hiện trên nhiều tỷ lệ có thể được nối với nhau, điều này không thể thực hiện được vì chúng có kích thước khác nhau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, CUDA):\n",
    "    modules = self.blocks[1:]\n",
    "    outputs = {}   #We cache the outputs for the route layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward` nhận ba đối số, `self`, đầu vào `x` và `CUDA`, nếu đúng, sẽ sử dụng GPU để tăng tốc forward pass.\n",
    "\n",
    "Ở đây, chúng tôi lặp qua `self.blocks [1:]` thay vì `self.blocks` vì phần tử đầu tiên của `self.blocks` là một khối `net` không phải là một phần của forward pass.\n",
    "\n",
    "Vì các lớp *route* và *shortcut* cần bản đồ đầu ra từ các lớp trước, chúng tôi lưu vào bộ nhớ cache các bản đồ tính năng đầu ra của mọi lớp trong `output` dict. Quan trọng là chỉ số của các lớp và các giá trị là feature maps.\n",
    "\n",
    "Như trường hợp với hàm `create_modules`, bây giờ chúng ta lặp qua `module_list` chứa các mô-đun của mạng. Điều cần chú ý ở đây là các mô-đun đã được nối theo thứ tự giống như chúng có trong tệp cấu hình. Điều này có nghĩa là, chúng ta có thể chỉ cần chạy đầu vào của mình qua từng mô-đun để có được đầu ra của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = 0     #This is explained a bit later\n",
    "for i, module in enumerate(modules):        \n",
    "    module_type = (module[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional và Upsample Layers\n",
    "Nếu mô-đun là một mô-đun convolution hoặc mô-đun upsample, đây là cách forward sẽ hoạt động."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if module_type == \"convolutional\" or module_type == \"upsample\":\n",
    "            x = self.module_list[i](x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Layer / Shortcut Layer\n",
    "Nếu bạn tìm code cho lớp route, chúng ta phải tính đến hai trường hợp (như được mô tả trong phần 2). Đối với trường hợp chúng ta phải ghép hai bản đồ đối tượng, chúng ta sử dụng hàm `torch.cat` với đối số thứ hai là 1. Điều này là do chúng ta muốn nối các bản đồ đối tượng theo độ sâu. (Trong PyTorch, đầu vào và đầu ra của lớp chập có định dạng `B X C X H X W`. Độ sâu tương ứng với kích thước kênh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        elif module_type == \"route\":\n",
    "            layers = module[\"layers\"]\n",
    "            layers = [int(a) for a in layers]\n",
    "\n",
    "            if (layers[0]) > 0:\n",
    "                layers[0] = layers[0] - i\n",
    "\n",
    "            if len(layers) == 1:\n",
    "                x = outputs[i + (layers[0])]\n",
    "\n",
    "            else:\n",
    "                if (layers[1]) > 0:\n",
    "                    layers[1] = layers[1] - i\n",
    "\n",
    "                map1 = outputs[i + layers[0]]\n",
    "                map2 = outputs[i + layers[1]]\n",
    "\n",
    "                x = torch.cat((map1, map2), 1)\n",
    "\n",
    "        elif  module_type == \"shortcut\":\n",
    "            from_ = int(module[\"from\"])\n",
    "            x = outputs[i-1] + outputs[i+from_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO (Detection Layer)\n",
    "Đầu ra của YOLO là một bản đồ đối tượng tích tụ có chứa các thuộc tính hộp giới hạn dọc theo độ sâu của bản đồ đối tượng. Các hộp giới hạn thuộc tính được dự đoán bởi một ô được xếp chồng lần lượt dọc theo nhau. Vì vậy, nếu bạn phải truy cập giới hạn thứ hai của ô tại (5,6), thì bạn sẽ phải lập chỉ mục nó bằng `map[5,6, (5 + C): 2 * (5 + C)]`. Biểu mẫu này rất bất tiện cho việc xử lý đầu ra chẳng hạn như tạo ngưỡng bởi độ tin cậy của đối tượng, thêm hiệu số lưới vào các trung tâm, áp dụng neo, v.v.\n",
    "\n",
    "Một vấn đề khác là vì việc phát hiện xảy ra ở ba tỷ lệ, kích thước của bản đồ dự đoán sẽ khác nhau. Mặc dù kích thước của ba bản đồ đối tượng địa lý là khác nhau, các hoạt động xử lý đầu ra được thực hiện trên chúng là tương tự nhau. Sẽ rất tuyệt nếu bạn phải thực hiện các hoạt động này trên một tensor duy nhất, thay vì ba tensor riêng biệt.\n",
    "\n",
    "Để khắc phục những vấn đề này, chúng tôi giới thiệu hàm `predict_transform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Chuyển đổi đầu ra\n",
    "Hàm `predict_transform` tồn tại trong tệp `util.py` và chúng tôi sẽ nhập hàm khi chúng tôi sử dụng nó trước lớp `Darknet`.\n",
    "\n",
    "Thêm các mục nhập vào đầu trang `util.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*predict_transform* nhận 5 tham số; *prediction* (đầu ra của chúng tôi), *inp_dim* (kích thước hình ảnh đầu vào), *anchors*, *num_classes* và cờ *CUDA* tùy chọn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA = True):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm predict_transform nhận một bản đồ tính năng phát hiện và biến nó thành một tensor 2-D, trong đó mỗi hàng của tensor tương ứng với các thuộc tính của một hộp giới hạn, theo thứ tự sau.\n",
    "\n",
    "![](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là code để thực hiện chuyển đổi trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_size = prediction.size(0)\n",
    "    stride =  inp_dim // prediction.size(2)\n",
    "    grid_size = inp_dim // stride\n",
    "    bbox_attrs = 5 + num_classes\n",
    "    num_anchors = len(anchors)\n",
    "    \n",
    "    prediction = prediction.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)\n",
    "    prediction = prediction.transpose(1,2).contiguous()\n",
    "    prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kích thước của neo phù hợp với các thuộc tính `height` và `width` của khối `net`. Các thuộc tính này mô tả kích thước của hình ảnh đầu vào, lớn hơn (theo hệ số bước) so với bản đồ phát hiện. Do đó, chúng ta phải chia các mỏ neo theo bước của bản đồ đối tượng địa lý phát hiện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    anchors = [(a[0]/stride, a[1]/stride) for a in anchors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chúng ta cần biến đổi đầu ra của mình theo các phương trình mà chúng ta đã thảo luận trong Phần 1.\n",
    "\n",
    "Sigmoid tọa độ x, y và điểm đối tượng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Sigmoid the  centre_X, centre_Y. and object confidencce\n",
    "    prediction[:,:,0] = torch.sigmoid(prediction[:,:,0])\n",
    "    prediction[:,:,1] = torch.sigmoid(prediction[:,:,1])\n",
    "    prediction[:,:,4] = torch.sigmoid(prediction[:,:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thêm hiệu số lưới vào dự đoán tọa độ trung tâm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Add the center offsets\n",
    "    grid = np.arange(grid_size)\n",
    "    a,b = np.meshgrid(grid, grid)\n",
    "\n",
    "    x_offset = torch.FloatTensor(a).view(-1,1)\n",
    "    y_offset = torch.FloatTensor(b).view(-1,1)\n",
    "\n",
    "    if CUDA:\n",
    "        x_offset = x_offset.cuda()\n",
    "        y_offset = y_offset.cuda()\n",
    "\n",
    "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1,num_anchors).view(-1,2).unsqueeze(0)\n",
    "\n",
    "    prediction[:,:,:2] += x_y_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng các neo cho các kích thước của hộp giới hạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #log space transform height and the width\n",
    "    anchors = torch.FloatTensor(anchors)\n",
    "\n",
    "    if CUDA:\n",
    "        anchors = anchors.cuda()\n",
    "\n",
    "    anchors = anchors.repeat(grid_size*grid_size, 1).unsqueeze(0)\n",
    "    prediction[:,:,2:4] = torch.exp(prediction[:,:,2:4])*anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng kích hoạt sigmoid cho điểm số của lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    prediction[:,:,5: 5 + num_classes] = torch.sigmoid((prediction[:,:, 5 : 5 + num_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều cuối cùng chúng tôi muốn làm ở đây là thay đổi kích thước bản đồ phát hiện thành kích thước của hình ảnh đầu vào. Các thuộc tính hộp giới hạn ở đây có kích thước theo bản đồ đối tượng (giả sử, 13 x 13). Nếu hình ảnh đầu vào là 416 x 416, chúng tôi nhân các thuộc tính với 32 hoặc biến sải chân."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[:,:,:4] *= stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều đó kết thúc phần thân của vòng lặp.\n",
    "\n",
    "Trả về các dự đoán ở cuối hàm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Xem lại Detection Layer\n",
    "Bây giờ chúng ta đã chuyển đổi các tensor đầu ra của mình, chúng ta có thể nối các bản đồ phát hiện ở ba tỷ lệ khác nhau thành một tensor lớn. Lưu ý rằng điều này không thể thực hiện được trước khi chúng tôi chuyển đổi, vì người ta không thể ghép các bản đồ đối tượng địa lý có các kích thước không gian khác nhau. Nhưng kể từ bây giờ, tensor đầu ra của chúng tôi chỉ hoạt động như một bảng với các hộp giới hạn vì nó là các hàng, việc nối là rất khả thi.\n",
    "\n",
    "Một trở ngại theo cách của chúng ta là chúng ta không thể khởi tạo một tensor rỗng, và sau đó nối một tensor không rỗng (có hình dạng khác) với nó. Vì vậy, chúng tôi trì hoãn việc khởi tạo bộ thu (tensor giữ các phát hiện) cho đến khi chúng tôi nhận được bản đồ phát hiện đầu tiên của mình, sau đó nối với bản đồ với nó khi chúng tôi nhận được các phát hiện tiếp theo.\n",
    "\n",
    "Lưu ý dòng `write = 0` ngay trước vòng lặp trong hàm forward. Cờ `write` được sử dụng để cho biết liệu chúng ta có gặp phải lần phát hiện đầu tiên hay không. Nếu ghi là 0, có nghĩa là bộ sưu tập chưa được khởi tạo. Nếu nó là 1, điều đó có nghĩa là bộ sưu tập đã được khởi tạo và chúng tôi chỉ có thể nối các bản đồ phát hiện của mình với nó.\n",
    "\n",
    "Bây giờ, chúng tôi đã trang bị cho mình hàm `predict_transform`, chúng tôi viết mã để xử lý các bản đồ tính năng phát hiện trong hàm `forward`.\n",
    "\n",
    "Ở đầu tệp `darknet.py` của bạn, hãy thêm nhập sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        elif module_type == 'yolo':        \n",
    "\n",
    "            anchors = self.module_list[i][0].anchors\n",
    "            #Get the input dimensions\n",
    "            inp_dim = int (self.net_info[\"height\"])\n",
    "\n",
    "            #Get the number of classes\n",
    "            num_classes = int (module[\"classes\"])\n",
    "\n",
    "            #Transform \n",
    "            x = x.data\n",
    "            x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
    "            if not write:              #if no collector has been intialised. \n",
    "                detections = x\n",
    "                write = 1\n",
    "\n",
    "            else:       \n",
    "                detections = torch.cat((detections, x), 1)\n",
    "\n",
    "        outputs[i] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chỉ cần trả lại các phát hiện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Kiểm tra chuyển tiếp\n",
    "\n",
    "Đây là một hàm tạo đầu vào giả. Chúng tôi sẽ chuyển đầu vào này vào mạng của chúng tôi. Trước khi chúng tôi viết hàm này, hãy lưu [hình ảnh](https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png) này vào thư mục làm việc của bạn. Nếu bạn đang sử dụng Linux, sau đó nhập."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, hãy xác định hàm ở đầu tệp `darknet.py` của bạn như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input():\n",
    "    img = cv2.imread(\"dog-cycle-car.png\")\n",
    "    img = cv2.resize(img, (416,416))          #Resize to the input dimension\n",
    "    img_ =  img[:,:,::-1].transpose((2,0,1))  # BGR -> RGB | H X W C -> C X H X W \n",
    "    img_ = img_[np.newaxis,:,:,:]/255.0       #Add a channel at 0 (for batch) | Normalise\n",
    "    img_ = torch.from_numpy(img_).float()     #Convert to float\n",
    "    img_ = Variable(img_)                     # Convert to Variable\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó, chúng tôi nhập mã sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "inp = get_test_input()\n",
    "pred = model(inp, torch.cuda.is_available())\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn sẽ thấy một đầu ra như thế nào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(  0  ,.,.) = \n",
    "   16.0962   17.0541   91.5104  ...     0.4336    0.4692    0.5279\n",
    "   15.1363   15.2568  166.0840  ...     0.5561    0.5414    0.5318\n",
    "   14.4763   18.5405  409.4371  ...     0.5908    0.5353    0.4979\n",
    "               ⋱                ...             \n",
    "  411.2625  412.0660    9.0127  ...     0.5054    0.4662    0.5043\n",
    "  412.1762  412.4936   16.0449  ...     0.4815    0.4979    0.4582\n",
    "  412.1629  411.4338   34.9027  ...     0.4306    0.5462    0.4138\n",
    "[torch.FloatTensor of size 1x10647x85]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kích thước của tensor này là `1 x 10647 x 85`. Kích thước đầu tiên là kích thước batch đơn giản là 1 vì chúng tôi đã sử dụng một hình ảnh duy nhất. Đối với mỗi hình ảnh trong một batch, chúng tôi có một bảng 10647 x 85. Hàng của mỗi bảng này đại diện cho một hộp giới hạn. (4 thuộc tính bbox, 1 điểm đối tượng và 80 điểm lớp)\n",
    "\n",
    "Tại thời điểm này, mạng của chúng ta có trọng số ngẫu nhiên và sẽ không tạo ra kết quả chính xác. Chúng tôi cần tải một tệp weight trong mạng của mình. Chúng tôi sẽ sử dụng tệp weight chính thức cho mục đích này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Downloading the Pre-trained Weights\n",
    "Tải xuống tệp weight vào thư mục detector của bạn. Lấy tệp weight [tại đây](https://pjreddie.com/media/files/yolov3.weights). Hoặc nếu bạn đang sử dụng Linux,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://pjreddie.com/media/files/yolov3.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Hiểu tệp Weights\n",
    "Tệp *Weight* chính thức là tệp nhị phân chứa các trọng số được lưu trữ theo kiểu nối tiếp.\n",
    "\n",
    "Phải hết sức cẩn thận khi đọc *weight*. Các *weight* chỉ được lưu trữ dưới dạng *float*, không có gì để hướng dẫn chúng ta xem chúng thuộc về lớp nào. Nếu bạn làm hỏng, không có gì ngăn cản bạn, chẳng hạn như weightng của lớp *batch norm* vào lớp *convolutional*. Vì bạn đang đọc *float*, không có cách nào để phân biệt weight thuộc về lớp nào. Do đó, chúng ta phải hiểu cách các weight được lưu trữ.\n",
    "\n",
    "Đầu tiên, các trọng số chỉ thuộc về hai loại lớp, hoặc lớp *batch norm* hoặc *convolutional*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight cho các lớp này được lưu trữ chính xác theo thứ tự như chúng xuất hiện trong tệp cấu hình. Vì vậy, nếu một khối `convolutional` được theo sau bởi một khối `shortcut` và sau đó là khối `shortcut` bởi một khối `convolutional` khác, Bạn sẽ mong đợi tệp chứa các weight của khối `convolutional` trước đó, tiếp theo là các weight của khối `convolutional` sau.\n",
    "\n",
    "Khi lớp `batch norm` xuất hiện trong một khối `convolutional`, không có sai lệch. Tuy nhiên, khi không có lớp batch norm, \"weight\" thiên vị phải đọc từ tệp.\n",
    "\n",
    "Sơ đồ sau đây tổng hợp cách lưu trữ các weight.\n",
    "\n",
    "![](https://blog.paperspace.com/content/images/2018/04/wts-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Tải Weights\n",
    "Hãy để chúng tôi viết một hàm tải weight. Nó sẽ là một chức năng thành viên của lớp `Darknet`. Nó sẽ lấy một đối số khác với `self`, đường dẫn của `weightfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(self, weightfile):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "160 byte đầu tiên của tệp weights lưu trữ 5 giá trị int32 tạo thành tiêu đề của tệp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Open the weights file\n",
    "    fp = open(weightfile, \"rb\")\n",
    "\n",
    "    #The first 5 values are header information \n",
    "    # 1. Major version number\n",
    "    # 2. Minor Version Number\n",
    "    # 3. Subversion number \n",
    "    # 4,5. Images seen by the network (during training)\n",
    "    header = np.fromfile(fp, dtype = np.int32, count = 5)\n",
    "    self.header = torch.from_numpy(header)\n",
    "    self.seen = self.header[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phần còn lại của các bit bây giờ đại diện cho trọng số, theo thứ tự được mô tả ở trên. Các trọng số được lưu trữ dưới dạng `float32` hoặc float 32-bit. Hãy tải phần còn lại của các trọng số trong một `np.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ptr = 0\n",
    "    for i in range(len(self.module_list)):\n",
    "        module_type = self.blocks[i + 1][\"type\"]\n",
    "\n",
    "        #If module_type is convolutional load weights\n",
    "        #Otherwise ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong vòng lặp, trước tiên chúng ta kiểm tra xem khối `convolutional` có `batch_normalise` True hay không. Dựa vào đó, chúng tôi tải weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if module_type == \"convolutional\":\n",
    "            model = self.module_list[i]\n",
    "            try:\n",
    "                batch_normalize = int(self.blocks[i+1][\"batch_normalize\"])\n",
    "            except:\n",
    "                batch_normalize = 0\n",
    "\n",
    "            conv = model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng tôi giữ một biến có tên `ptr` để theo dõi vị trí của chúng tôi trong mảng trọng số. Bây giờ, nếu `batch_normalize` là True, chúng ta tải trọng số như sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       if (batch_normalize):\n",
    "            bn = model[1]\n",
    "\n",
    "            #Get the number of weights of Batch Norm Layer\n",
    "            num_bn_biases = bn.bias.numel()\n",
    "\n",
    "            #Load the weights\n",
    "            bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "            ptr += num_bn_biases\n",
    "\n",
    "            bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
    "            ptr  += num_bn_biases\n",
    "\n",
    "            bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
    "            ptr  += num_bn_biases\n",
    "\n",
    "            bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
    "            ptr  += num_bn_biases\n",
    "\n",
    "            #Cast the loaded weights into dims of model weights. \n",
    "            bn_biases = bn_biases.view_as(bn.bias.data)\n",
    "            bn_weights = bn_weights.view_as(bn.weight.data)\n",
    "            bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
    "            bn_running_var = bn_running_var.view_as(bn.running_var)\n",
    "\n",
    "            #Copy the data to model\n",
    "            bn.bias.data.copy_(bn_biases)\n",
    "            bn.weight.data.copy_(bn_weights)\n",
    "            bn.running_mean.copy_(bn_running_mean)\n",
    "            bn.running_var.copy_(bn_running_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu batch_norm không đúng, chỉ cần tải các biases của lớp convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       else:\n",
    "            #Number of biases\n",
    "            num_biases = conv.bias.numel()\n",
    "\n",
    "            #Load the weights\n",
    "            conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])\n",
    "            ptr = ptr + num_biases\n",
    "\n",
    "            #reshape the loaded weights according to the dims of the model weights\n",
    "            conv_biases = conv_biases.view_as(conv.bias.data)\n",
    "\n",
    "            #Finally copy the data\n",
    "            conv.bias.data.copy_(conv_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, chúng tôi tải trọng số của lớp convolutional cuối cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us load the weights for the Convolutional layers\n",
    "num_weights = conv.weight.numel()\n",
    "\n",
    "#Do the same as above for weights\n",
    "conv_weights = torch.from_numpy(weights[ptr:ptr+num_weights])\n",
    "ptr = ptr + num_weights\n",
    "\n",
    "conv_weights = conv_weights.view_as(conv.weight.data)\n",
    "conv.weight.data.copy_(conv_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta đã thực hiện xong hàm này và bây giờ bạn có thể tải trọng số trong đối tượng Darknet của mình bằng cách gọi hàm `load_weights` trên đối tượng `darknet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"cfg/yolov3.cfg\")\n",
    "model.load_weights(\"yolov3.weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ngưỡng tin cậy và Non-maximum Suppression\n",
    "Trong các phần trước, chúng ta đã xây dựng một mô hình đưa ra một số phát hiện đối tượng với một hình ảnh đầu vào. Nói một cách chính xác, đầu ra của chúng ta là một tensor của hình dạng B x 10647 x 85. B là số hình ảnh trong một lô, 10647 là số hộp giới hạn được dự đoán trên mỗi hình ảnh và 85 là số thuộc tính hộp giới hạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
