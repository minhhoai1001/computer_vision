{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection - OpenCV, Dlib and Deep Learning\n",
    "# 1. Introduction\n",
    "In this tutorial, we will discuss the various Face Detection methods in OpenCV and Dlib and compare the methods quantitatively. We will share code in C++ and Python for the following Face Detectors :\n",
    "\n",
    "1. Haar Cascade Face Detector in OpenCV\n",
    "2. Deep Learning based Face Detector in OpenCV\n",
    "3. HoG Face Detector in Dlib\n",
    "4. Deep Learning based Face Detector in Dlib\n",
    "\n",
    "We will not go into the theory of any of them and only discuss their usage. We will also share some rules of thumb on which model to prefer according to your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Haar Cascade Face Detector in OpenCV\n",
    "Haar Cascade based Face Detector was the state-of-the-art in Face Detection for many years since 2001, when it was introduced by Viola and Jones. There has been many improvements in the recent years. OpenCV has many Haar based models which can be found [here](https://github.com/opencv/opencv/tree/master/data/haarcascades)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('models/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('data/MU.jpg', cv2.IMREAD_COLOR)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"Face Detection Comparison\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippet loads the haar cascade model file and applies it to a grayscale image. the output is a list containing the detected faces. Each member of the list is again a list with 4 elements indicating the (x, y) coordinates of the top-left corner and the width and height of the detected face.\n",
    "\n",
    "## Pros\n",
    "1. Works almost real-time on CPU\n",
    "2. Simple Architecture\n",
    "3. Detects faces at different scales\n",
    "\n",
    "## Cons\n",
    "1. The major drawback of this method is that it gives a lot of False predictions.\n",
    "2. Doesn’t work on non-frontal images.\n",
    "3. Doesn’t work under occlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DNN Face Detector in OpenCV\n",
    "This model was included in OpenCV from version 3.3. It is based on [**Single-Shot-Multibox detector**](https://arxiv.org/abs/1512.02325) and uses **ResNet-10** Architecture as backbone. The model was trained using images available from the web, but the source is not disclosed. OpenCV provides 2 models for this face detector.\n",
    "\n",
    "* Floating point 16 version of the original caffe implementation ( 5.4 MB )\n",
    "* 8 bit quantized version using Tensorflow ( 2.7 MB )\n",
    "\n",
    "We have included both the models along with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] computing object detections...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "modelFile = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"models/deploy.prototxt\"\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "# load the input image and construct an input blob for the image\n",
    "# by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "image = cv2.imread(\"data/MU.jpg\")\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,\n",
    "    (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "# pass the blob through the network and obtain the detections and\n",
    "# predictions\n",
    "print(\"[INFO] computing object detections...\")\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# loop over the detections\n",
    "for i in range(0, detections.shape[2]):\n",
    "    # extract the confidence (i.e., probability) associated with the\n",
    "    # prediction\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # filter out weak detections by ensuring the `confidence` is\n",
    "    # greater than the minimum confidence\n",
    "    if confidence > 0.2:\n",
    "        # compute the (x, y)-coordinates of the bounding box for the\n",
    "        # object\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    " \n",
    "        # draw the bounding box of the face along with the associated\n",
    "        # probability\n",
    "        text = \"{:.2f}%\".format(confidence * 100)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "            (0, 0, 255), 2)\n",
    "        cv2.putText(image, text, (startX, y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, the image is converted to a blob and passed through the network using the `forward()` function. The output detections is a 4-D matrix, where\n",
    "\n",
    "* The 3rd dimension iterates over the detected faces. (i is the iterator over the number of faces)\n",
    "* The fourth dimension contains information about the bounding box and score for each face. For example, `detections[0,0,0,2]` gives the confidence score for the first face, and `detections[0,0,0,3:6]` give the bounding box.\n",
    "\n",
    "The output coordinates of the bounding box are normalized between [0,1]. Thus the coordinates should be multiplied by the height and width of the original image to get the correct bounding box on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros\n",
    "The method has the following merits :\n",
    "\n",
    "1. Most accurate out of the four methods\n",
    "2. Runs at real-time on CPU\n",
    "3. Works for different face orientations – up, down, left, right, side-face etc.\n",
    "4. Works even under substantial occlusion\n",
    "5. Detects faces across various scales ( detects big as well as tiny faces )\n",
    "\n",
    "The DNN based detector overcomes all the drawbacks of Haar cascade based detector, without compromising on any benefit provided by Haar. We could not see any major drawback for this method except that it is slower than the Dlib HoG based Face Detector discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. HoG Face Detector in Dlib\n",
    "This is a widely used face detection model, based on HoG features and SVM. You can read more about HoG in [this post](https://www.learnopencv.com/histogram-of-oriented-gradients/). The model is built out of 5 HOG filters – front looking, left looking, right looking, front looking but rotated left, and a front looking but rotated right. The model comes embedded in the [header file](https://github.com/davisking/dlib/blob/master/dlib/image_processing/frontal_face_detector.h) itself.\n",
    "\n",
    "The dataset used for training, consists of 2825 images which are obtained from LFW dataset and manually annotated by Davis King, the author of Dlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "image = cv2.imread(\"data/MU.jpg\")\n",
    "hogFaceDetector = dlib.get_frontal_face_detector()\n",
    "faceRects = hogFaceDetector(image, 0)\n",
    "for faceRect in faceRects:\n",
    "    x1 = faceRect.left()\n",
    "    y1 = faceRect.top()\n",
    "    x2 = faceRect.right()\n",
    "    y2 = faceRect.bottom()\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2),(0, 0, 255), 2)\n",
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we first load the face detector. Then we pass it the image through the detector. The second argument is the number of times we want to upscale the image. The more you upscale, the better are the chances of detecting smaller faces. However, upscaling the image will have substantial impact on the computation speed. The output is in the form of a list of faces with the (x, y) coordinates of the diagonal corners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros\n",
    "1. Fastest method on CPU\n",
    "2. Works very well for frontal and slightly non-frontal faces\n",
    "3. Light-weight model as compared to the other three.\n",
    "4. Works under small occlusion\n",
    "\n",
    "Basically, this method works under most cases except a few as discussed below.\n",
    "\n",
    "## Cons\n",
    "1. The major drawback is that it does not detect small faces as it is trained for minimum face size of 80×80. Thus, you need to make sure that the face size should be more than that in your application. You can however, train your own face detector for smaller sized faces.\n",
    "2. The bounding box often excludes part of forehead and even part of chin sometimes.\n",
    "3. Does not work very well under substantial occlusion\n",
    "4. Does not work for side face and extreme non-frontal faces, like looking down or up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CNN Face Detector in Dlib\n",
    "This method uses a **Maximum-Margin Object Detector** ( [MMOD](https://arxiv.org/pdf/1502.00046.pdf) ) with CNN based features. The training process for this method is very simple and you don’t need a large amount of data to train a custom object detector. For more information on training, visit [the website](http://blog.dlib.net/2016/10/easily-create-high-quality-object.html).\n",
    "\n",
    "The model can be downloaded from the [dlib-models repository](https://github.com/davisking/dlib-models).\n",
    "It uses a dataset manually labeled by its Author, Davis King, consisting of images from various datasets like ImageNet, PASCAL VOC, VGG, WIDER, Face Scrub. It contains 7220 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 4\n",
      "Detection 0: Left: 257 Top: 157 Right: 296 Bottom: 197 Confidence: 1.1261976957321167\n",
      "Detection 1: Left: 359 Top: 37 Right: 416 Bottom: 94 Confidence: 1.114716649055481\n",
      "Detection 2: Left: 462 Top: 55 Right: 519 Bottom: 112 Confidence: 1.0968915224075317\n",
      "Detection 3: Left: 146 Top: 89 Right: 202 Bottom: 146 Confidence: 1.088628888130188\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "\n",
    "model_path = \"models/mmod_human_face_detector.dat\"\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(model_path)\n",
    "img = cv2.imread(\"data/MU.jpg\")\n",
    "# The 1 in the second argument indicates that we should upsample the image\n",
    "# 1 time.  This will make everything bigger and allow us to detect more faces.\n",
    "dets = cnn_face_detector(img, 1)\n",
    "print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "for i, d in enumerate(dets):\n",
    "    x1 = d.rect.left()\n",
    "    y1 = d.rect.top()\n",
    "    x2 = d.rect.right()\n",
    "    y2 = d.rect.bottom()\n",
    "    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {} Confidence: {}\".format(\n",
    "        i, d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom(), d.confidence))\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2),(0, 0, 255), 2) \n",
    "\n",
    "rects = dlib.rectangles()\n",
    "rects.extend([d.rect for d in dets])\n",
    "\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is similar to the HoG detector except that in this case, we load the cnn face detection model. Also, the coordinates are present inside a rect object.\n",
    "\n",
    "## Pros\n",
    "1. Works for different face orientations\n",
    "2. Robust to occlusion\n",
    "3. Works very fast on GPU\n",
    "4. Very easy training process\n",
    "\n",
    "## Cons\n",
    "1. Very slow on CPU\n",
    "2. Does not detect small faces as it is trained for minimum face size of 80×80. Thus, you need to make sure that the face size should be more than that in your application. You can however, train your own face detector for smaller sized faces.\n",
    "3. The bounding box is even smaller than the HoG detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Accuracy Comparison\n",
    "I tried to evaluate the 4 models using the FDDB dataset using [the script used for evaluating the OpenCV-DNN model](https://github.com/opencv/opencv/blob/master/modules/dnn/misc/face_detector_accuracy.py). However, I found surprising results. *Dlib* had worse numbers than *Haar*, although visually dlib outputs look much better. Given below are the Precision scores for the 4 methods.\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2018/10/face-detection-coco-comparison.jpg)\n",
    "\n",
    "Where,\n",
    "* AP_50 = Precision when overlap between Ground Truth and predicted bounding box is at least 50% ( IoU = 50% )\n",
    "* AP_75 = Precision when overlap between Ground Truth and predicted bounding box is at least 75% ( IoU = 75% )\n",
    "* AP_Small = Average Precision for small size faces ( Average of IoU = 50% to 95% )\n",
    "* AP_medium = Average Precision for medium size faces ( Average of IoU = 50% to 95% )\n",
    "* AP_Large = Average Precision for large size faces ( Average of IoU = 50% to 95% )\n",
    "* mAP = Average precision across different IoU ( Average of IoU = 50% to 95% )\n",
    "\n",
    "On closer inspection I found that this evaluation is not fair for Dlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Evaluating accuracy the wrong way!\n",
    "According to my analysis, the reasons for lower numbers for dlib are as follows :\n",
    "\n",
    "1. The major reason is that dlib was trained using standard datasets BUT, without their annotations. The images were annotated by its author. Thus, I found that even when the faces are detected, **the bounding boxes are quite different** than that of Haar or OpenCV-DNN. They were smaller and often clipped parts of forehead and chin as shown below.\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2018/10/fd-acc-result3-e1539872783684.jpg)\n",
    "\n",
    "This can be further explained from the AP_50 and AP_75 scores in the above graph. AP_X means precision when there is X% overlap between ground truth and detected boxes. The AP_75 scores for dlib models are 0 although AP_50 scores are higher than that of Haar. This only means that the Dlib models are able to detect **more faces** than that of Haar, but the smaller bounding boxes of dlib lower their AP_75 and other numbers.\n",
    "\n",
    "2. The second reason is that dlib is unable to detect small faces which further drags down the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Speed Comparison\n",
    "We used a 300×300 image for the comparison of the methods. The MMOD detector can be run on a GPU, but the support for NVIDIA GPUs in OpenCV is still not there. So, we evaluate the methods on CPU only and also report result for MMOD on GPU as well as CPU.\n",
    "\n",
    "Hardware used:\n",
    "* Processor : Intel Core i7 6850K – 6 Core\n",
    "* RAM : 32 GB\n",
    "* GPU : NVIDIA GTX 1080 Ti with 11 GB RAM\n",
    "* OS : Linux 16.04 LTS\n",
    "* Programming Language : Python\n",
    "\n",
    "We run each method 10000 times on the given image and take 10 such iterations and average the time taken. Given below are the results.\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2018/10/face-detection-speed-comparison.jpg)\n",
    "\n",
    "As you can see that for the image of this size, **all the methods perform in real-time**, except MMOD. **MMOD detector is very fast on a GPU but is very slow on a CPU**.\n",
    "\n",
    "It should also be noted that these numbers can be different on different systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Comparison under various conditions\n",
    "Apart from accuracy and speed, there are some other factors which help us decide which one to use. In this section we will compare the methods on the basis of various other factors which are also important.\n",
    "\n",
    "## 7.1. Detection across scale\n",
    "We will see an example where, in the same video, the person goes back n forth, thus making the face smaller and bigger. We notice that the OpenCV DNN detects all the faces while Dlib detects only those faces which are bigger in size. We also show the size of the detected face along with the bounding box.\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2018/10/face-detection-scale-comparison.gif)\n",
    "\n",
    "It can be seen that dlib based methods are able to detect faces of size upto ~(70×70) after which they fail to detect. As we discussed earlier, I think this is the major drawback of Dlib based methods. Since it is not possible to know the size of the face before-hand in most cases. We can get rid of this problem by upscaling the image, but then the speed advantage of dlib as compared to OpenCV-DNN goes away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Non-frontal Face\n",
    "Non-frontal can be looking towards right, left, up, down. Again, to be fair with dlib, we make sure the face size is more than 80×80. Given below are some examples.\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2018/10/fd-non-frontal-result2.jpg)\n",
    "\n",
    "As expected, Haar based detector fails totally. HoG based detector does detect faces for left or right looking faces ( since it was trained on them ) but not as accurately as the DNN based detectors of OpenCV and Dlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Occlusion\n",
    "Let us see how well the methods perform under occlusion.\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2018/10/fd-occlusion-result1.jpg)\n",
    "\n",
    "Again, the DNN methods outperform the other two, with OpenCV-DNN slightly better than Dlib-MMOD. This is mainly because the CNN features are much more robust than HoG or Haar features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conclusion\n",
    "We had discussed the pros and cons of each method in the respective sections. I recommend to try both OpenCV-DNN and HoG methods for your application and decide accordingly. We share some tips to get started.\n",
    "\n",
    "**General Case**\n",
    "\n",
    "In most applications, we won’t know the size of the face in the image before-hand. Thus, it is better to use OpenCV – DNN method as it is pretty fast and very accurate, even for small sized faces. It also detects faces at various angles. We recommend to use **OpenCV-DNN** in most\n",
    "\n",
    "**For medium to large image sizes**\n",
    "\n",
    "Dlib HoG is the fastest method on CPU. But it does not detect small sized faces ( < 70x70 ). So, if you know that your application will not be dealing with very small sized faces ( for example a selfie app ), then HoG based Face detector is a better option. Also, If you can use a GPU, then **MMOD face detector** is the best option as it is very fast on GPU and also provides detection at various angles.\n",
    "\n",
    "**High resolution images**\n",
    "\n",
    "Since feeding high resolution images is not possible to these algorithms ( for computation speed ), **HoG / MMOD** detectors might fail when you scale down the image. On the other hand, **OpenCV-DNN** method can be used for these since it detects small faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Source: [learnopencv](https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
